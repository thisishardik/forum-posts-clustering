{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4646c776",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gensim in c:\\users\\hp\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (4.1.2)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using pip version 10.0.1, however version 21.3.1 is available.\n",
      "You should consider upgrading via the 'python -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Requirement already satisfied: Cython==0.29.23 in c:\\users\\hp\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from gensim) (0.29.23)\n",
      "Requirement already satisfied: numpy>=1.17.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from gensim) (1.19.5)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in c:\\users\\hp\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from gensim) (5.2.1)\n",
      "Requirement already satisfied: scipy>=0.18.1 in c:\\users\\hp\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from gensim) (1.7.1)\n",
      "Requirement already satisfied: nltk in c:\\users\\hp\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (3.6.5)\n",
      "Requirement already satisfied: tqdm in c:\\users\\hp\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from nltk) (4.62.3)\n",
      "Requirement already satisfied: click in c:\\users\\hp\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from nltk) (8.0.3)\n",
      "Requirement already satisfied: joblib in c:\\users\\hp\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from nltk) (1.1.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\hp\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from nltk) (2021.11.2)\n",
      "Requirement already satisfied: colorama; platform_system == \"Windows\" in c:\\users\\hp\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from tqdm->nltk) (0.4.4)\n",
      "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in c:\\users\\hp\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from click->nltk) (4.8.1)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in c:\\users\\hp\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from importlib-metadata; python_version < \"3.8\"->click->nltk) (3.7.4.3)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\hp\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from importlib-metadata; python_version < \"3.8\"->click->nltk) (3.6.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using pip version 10.0.1, however version 21.3.1 is available.\n",
      "You should consider upgrading via the 'python -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting wget\n",
      "  Downloading https://files.pythonhosted.org/packages/47/6a/62e288da7bcda82b935ff0c6cfe542970f04e29c756b0e147251b2fb251f/wget-3.2.zip\n",
      "Building wheels for collected packages: wget\n",
      "  Running setup.py bdist_wheel for wget: started\n",
      "  Running setup.py bdist_wheel for wget: finished with status 'done'\n",
      "  Stored in directory: C:\\Users\\HP\\AppData\\Local\\pip\\Cache\\wheels\\40\\15\\30\\7d8f7cea2902b4db79e3fea550d7d7b85ecb27ef992b618f3f\n",
      "Successfully built wget\n",
      "Installing collected packages: wget\n",
      "Successfully installed wget-3.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using pip version 10.0.1, however version 21.3.1 is available.\n",
      "You should consider upgrading via the 'python -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!pip install gensim\n",
    "!pip install nltk\n",
    "!pip install wget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3a0bf208",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "import nltk\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models import Doc2Vec\n",
    "from gensim.models import KeyedVectors\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "import tensorflow as tf\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "import wget\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "# nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9f41bcb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(tf.config.list_physical_devices('GPU'))\n",
    "# tf.debugging.set_log_device_placement(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "003576d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "forum_posts = pd.read_csv('ForumMessages.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5b1da953",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>ForumTopicId</th>\n",
       "      <th>PostUserId</th>\n",
       "      <th>PostDate</th>\n",
       "      <th>ReplyToForumMessageId</th>\n",
       "      <th>Message</th>\n",
       "      <th>Medal</th>\n",
       "      <th>MedalAwardDate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>28</td>\n",
       "      <td>16</td>\n",
       "      <td>368</td>\n",
       "      <td>05/12/2010 04:39:30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Here are some papers that analyze Eurovision v...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>29</td>\n",
       "      <td>16</td>\n",
       "      <td>368</td>\n",
       "      <td>05/12/2010 04:39:30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>More research... enjoy&lt;br&gt;&lt;br&gt;Love thy Neighbo...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>993</td>\n",
       "      <td>133</td>\n",
       "      <td>2691</td>\n",
       "      <td>10/10/2010 02:39:04</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;div&gt;@Nan&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;Isn't X_i s...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>996</td>\n",
       "      <td>133</td>\n",
       "      <td>2958</td>\n",
       "      <td>10/10/2010 02:39:04</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Brad,&lt;br&gt;It is not. Y_i is defined as I (S_{i+...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1350</td>\n",
       "      <td>214</td>\n",
       "      <td>4284</td>\n",
       "      <td>12/01/2010 05:54:28</td>\n",
       "      <td>NaN</td>\n",
       "      <td>After I specify the adress of my result file a...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Id  ForumTopicId  PostUserId             PostDate  ReplyToForumMessageId  \\\n",
       "0    28            16         368  05/12/2010 04:39:30                    NaN   \n",
       "1    29            16         368  05/12/2010 04:39:30                    NaN   \n",
       "2   993           133        2691  10/10/2010 02:39:04                    NaN   \n",
       "3   996           133        2958  10/10/2010 02:39:04                    NaN   \n",
       "4  1350           214        4284  12/01/2010 05:54:28                    NaN   \n",
       "\n",
       "                                             Message  Medal MedalAwardDate  \n",
       "0  Here are some papers that analyze Eurovision v...    NaN            NaN  \n",
       "1  More research... enjoy<br><br>Love thy Neighbo...    NaN            NaN  \n",
       "2  <div>@Nan</div><div><br></div><div>Isn't X_i s...    NaN            NaN  \n",
       "3  Brad,<br>It is not. Y_i is defined as I (S_{i+...    NaN            NaN  \n",
       "4  After I specify the adress of my result file a...    NaN            NaN  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forum_posts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f957a3ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = forum_posts.Message.astype('str').tolist()\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "sentences_tokenized = [w.lower() for w in sentences]\n",
    "sentences_tokenized = [tokenizer.tokenize(i) for i in sentences_tokenized]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bf2b0233",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['here',\n",
       "  'are',\n",
       "  'some',\n",
       "  'papers',\n",
       "  'that',\n",
       "  'analyze',\n",
       "  'eurovision',\n",
       "  'voting',\n",
       "  'patterns',\n",
       "  'you',\n",
       "  'might',\n",
       "  'find',\n",
       "  'some',\n",
       "  'of',\n",
       "  'them',\n",
       "  'helpful',\n",
       "  'br',\n",
       "  'br',\n",
       "  'gatherer',\n",
       "  '2006',\n",
       "  'br',\n",
       "  'comparison',\n",
       "  'of',\n",
       "  'eurovision',\n",
       "  'song',\n",
       "  'contest',\n",
       "  'simulation',\n",
       "  'with',\n",
       "  'actual',\n",
       "  'results',\n",
       "  'reveals',\n",
       "  'shifting',\n",
       "  'patterns',\n",
       "  'of',\n",
       "  'collusive',\n",
       "  'voting',\n",
       "  'alliances',\n",
       "  'br',\n",
       "  'a',\n",
       "  'target',\n",
       "  '_blank',\n",
       "  'title',\n",
       "  'http',\n",
       "  'jasss',\n",
       "  'soc',\n",
       "  'surrey',\n",
       "  'ac',\n",
       "  'uk',\n",
       "  '9',\n",
       "  '2',\n",
       "  '1',\n",
       "  'html',\n",
       "  'mce_href',\n",
       "  'http',\n",
       "  'jasss',\n",
       "  'soc',\n",
       "  'surrey',\n",
       "  'ac',\n",
       "  'uk',\n",
       "  '9',\n",
       "  '2',\n",
       "  '1',\n",
       "  'html',\n",
       "  'href',\n",
       "  'http',\n",
       "  'jasss',\n",
       "  'soc',\n",
       "  'surrey',\n",
       "  'ac',\n",
       "  'uk',\n",
       "  '9',\n",
       "  '2',\n",
       "  '1',\n",
       "  'html',\n",
       "  'http',\n",
       "  'jasss',\n",
       "  'soc',\n",
       "  'surrey',\n",
       "  'ac',\n",
       "  'uk',\n",
       "  '9',\n",
       "  '2',\n",
       "  '1',\n",
       "  'html',\n",
       "  'br',\n",
       "  'a',\n",
       "  'br',\n",
       "  'the',\n",
       "  'eurovision',\n",
       "  'song',\n",
       "  'contest',\n",
       "  'is',\n",
       "  'voting',\n",
       "  'political',\n",
       "  'or',\n",
       "  'cultural',\n",
       "  'br',\n",
       "  'ginburgh',\n",
       "  'and',\n",
       "  'noury',\n",
       "  '2006',\n",
       "  'br',\n",
       "  'a',\n",
       "  'target',\n",
       "  '_blank',\n",
       "  'title',\n",
       "  'http',\n",
       "  '164',\n",
       "  '15',\n",
       "  '69',\n",
       "  '62',\n",
       "  'ecare',\n",
       "  'personal',\n",
       "  'ginsburgh',\n",
       "  'papers',\n",
       "  '153',\n",
       "  'eurovision',\n",
       "  'pdf',\n",
       "  'mce_href',\n",
       "  'http',\n",
       "  '164',\n",
       "  '15',\n",
       "  '69',\n",
       "  '62',\n",
       "  'ecare',\n",
       "  'personal',\n",
       "  'ginsburgh',\n",
       "  'papers',\n",
       "  '153',\n",
       "  'eurovision',\n",
       "  'pdf',\n",
       "  'href',\n",
       "  'http',\n",
       "  '164',\n",
       "  '15',\n",
       "  '69',\n",
       "  '62',\n",
       "  'ecare',\n",
       "  'personal',\n",
       "  'ginsburgh',\n",
       "  'papers',\n",
       "  '153',\n",
       "  'eurovision',\n",
       "  'pdf',\n",
       "  'http',\n",
       "  '164',\n",
       "  '15',\n",
       "  '69',\n",
       "  '62',\n",
       "  'ecare',\n",
       "  'personal',\n",
       "  'ginsburgh',\n",
       "  'papers',\n",
       "  '153',\n",
       "  'eurovision',\n",
       "  'pdf',\n",
       "  'a',\n",
       "  'br',\n",
       "  'br',\n",
       "  'fenn',\n",
       "  'suleman',\n",
       "  'efstathiou',\n",
       "  'and',\n",
       "  'johnson',\n",
       "  '2008',\n",
       "  'br',\n",
       "  'a',\n",
       "  'target',\n",
       "  '_blank',\n",
       "  'title',\n",
       "  'http',\n",
       "  'arxiv',\n",
       "  'org',\n",
       "  'pdf',\n",
       "  'physics',\n",
       "  '0505071',\n",
       "  'mce_href',\n",
       "  'http',\n",
       "  'arxiv',\n",
       "  'org',\n",
       "  'pdf',\n",
       "  'physics',\n",
       "  '0505071',\n",
       "  'href',\n",
       "  'http',\n",
       "  'arxiv',\n",
       "  'org',\n",
       "  'pdf',\n",
       "  'physics',\n",
       "  '0505071',\n",
       "  'http',\n",
       "  'arxiv',\n",
       "  'org',\n",
       "  'pdf',\n",
       "  'physics',\n",
       "  '0505071',\n",
       "  'a',\n",
       "  'br',\n",
       "  'br',\n",
       "  'the',\n",
       "  'eurovision',\n",
       "  'song',\n",
       "  'contest',\n",
       "  'as',\n",
       "  'a',\n",
       "  'friendship',\n",
       "  'network',\n",
       "  'br',\n",
       "  'dekker',\n",
       "  '2007',\n",
       "  'br',\n",
       "  'a',\n",
       "  'title',\n",
       "  'http',\n",
       "  'members',\n",
       "  'ozemail',\n",
       "  'com',\n",
       "  'au',\n",
       "  'dekker',\n",
       "  'ozemail',\n",
       "  'com',\n",
       "  'au',\n",
       "  'connections07',\n",
       "  'pdf',\n",
       "  'mce_href',\n",
       "  'http',\n",
       "  'members',\n",
       "  'ozemail',\n",
       "  'com',\n",
       "  'au',\n",
       "  'dekker',\n",
       "  'ozemail',\n",
       "  'com',\n",
       "  'au',\n",
       "  'connections07',\n",
       "  'pdf',\n",
       "  'href',\n",
       "  'http',\n",
       "  'members',\n",
       "  'ozemail',\n",
       "  'com',\n",
       "  'au',\n",
       "  '7edekker',\n",
       "  'ozemail',\n",
       "  'com',\n",
       "  'au',\n",
       "  'connections07',\n",
       "  'pdf',\n",
       "  'http',\n",
       "  'members',\n",
       "  'ozemail',\n",
       "  'com',\n",
       "  'au',\n",
       "  'dekker',\n",
       "  'ozemail',\n",
       "  'com',\n",
       "  'au',\n",
       "  'connections07',\n",
       "  'pdf',\n",
       "  'a',\n",
       "  'br',\n",
       "  'br',\n",
       "  'mce_bogus',\n",
       "  '1']]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences_tokenized[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f369ee2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1344027\n"
     ]
    }
   ],
   "source": [
    "model = Word2Vec(min_count=1)\n",
    "model.build_vocab(sentences_tokenized)\n",
    "total_examples = model.corpus_count\n",
    "print(total_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ef00c0c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(242194096, 321914325)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.intersect_word2vec_format(\"GoogleNews-vectors-negative300.bin\", binary=True, lockf=1.0)\n",
    "model.train(sentences_tokenized, total_examples=total_examples, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3e29c3e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gensim model\n",
    "model.save(\"forum_posts_word2vec_gensim.model\")\n",
    "\n",
    "# word2vec model\n",
    "model.wv.save_word2vec_format(\"forum_posts_word2vec.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb29d7a5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
